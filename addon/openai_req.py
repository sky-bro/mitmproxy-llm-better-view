import logging
import json
from typing import Any, List, Union

from mitmproxy.contentviews._api import Contentview
from mitmproxy import contentviews
from mitmproxy.http import Request

DEFAULT_INDENT = 0


def multi_line_splitter(line: int) -> str:
    # ç”Ÿæˆlineä¸ª'\n-'
    return "\n " * line + "\n"


def format_content(content: Union[str, List[Any]]) -> str:
    """æ ¼å¼åŒ–contentå†…å®¹ï¼Œå¤„ç†å­—ç¬¦ä¸²å’Œå¯¹è±¡æ•°ç»„çš„æƒ…å†µ"""
    if not content:
        return ""

    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
    if isinstance(content, str):
        return content.strip()

    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œéœ€è¦å¤„ç†æ¯ä¸ªå¯¹è±¡
    if isinstance(content, list):
        result_parts = []
        for item in content:
            if isinstance(item, str):
                result_parts.append(item)
            elif isinstance(item, dict):
                # æ£€æŸ¥typeå±æ€§
                item_type = item.get("type", "")
                if item_type == "text":
                    # å¤„ç†æ–‡æœ¬ç±»å‹
                    text_content = item.get("text", "")
                    if isinstance(text_content, str):
                        result_parts.append(text_content)
                    elif isinstance(text_content, dict):
                        # å¦‚æœtext_contentæ˜¯ä¸€ä¸ªå¯¹è±¡ï¼ŒåŒ…å«valueå’Œannotationså­—æ®µ
                        value = text_content.get("value", "")
                        annotations = text_content.get("annotations", [])
                        result_parts.append(value)
                        # å¦‚æœéœ€è¦æ˜¾ç¤ºannotationsï¼Œå¯ä»¥æ·»åŠ åˆ°ç»“æœä¸­
                        if annotations:
                            result_parts.append(f"[annotations: {json.dumps(annotations, ensure_ascii=False)}]")
                else:
                    # å…¶ä»–ç±»å‹çš„å¯¹è±¡ï¼Œç›´æ¥è½¬ä¸ºJSONå­—ç¬¦ä¸²
                    result_parts.append(json.dumps(item, ensure_ascii=False))
            else:
                # å…¶ä»–ç±»å‹ï¼Œè½¬ä¸ºå­—ç¬¦ä¸²
                result_parts.append(str(item))
        return "\n---\n".join(result_parts)

    # å…¶ä»–æƒ…å†µï¼Œè½¬ä¸ºå­—ç¬¦ä¸²
    return str(content)


def indent_text(text: str, n: int) -> str:
    """å°†å¤šè¡Œæ–‡æœ¬æ•´ä½“ç¼©è¿› n ä¸ªç©ºæ ¼"""
    if not text:
        return text
    indent = " " * n
    indented_lines = [
        (indent + line) if line.strip() else line for line in text.splitlines()
    ]
    return "\n".join(indented_lines)


def format_json_text(text: str) -> str:
    """å°†JSONæ–‡æœ¬æ ¼å¼åŒ–ä¸ºmarkdownä»£ç å—"""
    if not text:
        return text
    # å°è¯•è§£æJSONå¹¶ç¾åŒ–
    try:
        parsed_json = json.loads(text)
        formatted_json = json.dumps(parsed_json, indent=2, ensure_ascii=False)
        return f"```json\n{formatted_json}\n```"
    except json.JSONDecodeError:
        # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œåˆ™ä¿æŒåŸæ ·
        return text


split_line = "\n----------------------------------\n"


def handle_request_basis(body: Any) -> str:
    """å¤„ç†è¯·æ±‚çš„åŸºç¡€ä¿¡æ¯: model,temperature,stream,max_tokens,messages.length,tools.length"""
    basic_result = ""
    model = body.get("model", "N/A")
    temperature = body.get("temperature", "N/A")
    stream = body.get("stream", "N/A")
    max_tokens = body.get("max_tokens", "N/A")
    messages_length = len(body.get("messages", []))
    tools_length = len(body.get("tools", []))
    # è®¡ç®—æ‰€æœ‰æ ‡ç­¾çš„æœ€å¤§é•¿åº¦ï¼Œå®ç°å³å¯¹é½
    labels = ["model", "temperature", "stream", "max_tokens", "messages", "tools"]
    max_label_len = max(len(label) for label in labels) + 2
    basic_result += f'{"model":<{max_label_len}}:   {model}\n'
    basic_result += f'{"temperature":<{max_label_len}}:   {temperature}\n'
    basic_result += f'{"stream":<{max_label_len}}:   {stream}\n'
    basic_result += f'{"max_tokens":<{max_label_len}}:   {max_tokens}\n'
    basic_result += f'{"messages":<{max_label_len}}:   {messages_length}\n'
    basic_result += f'{"tools":<{max_label_len}}:   {tools_length}\n'
    return basic_result


def handle_messages(messages: List[Any]) -> str:
    prompt_result = f"## MessagesğŸ“– ({len(messages)})\n"
    for i, message in enumerate(messages):
        role = message.get("role")
        raw_content = message.get("content", "")
        content = format_content(raw_content)
        tool_calls = message.get("tool_calls", [])
        tool_call_id = message.get("tool_call_id", "")
        # logging.info(f'ğŸ”[{i}] role: {role}, content: {content}')
        prompt_result += f"### ğŸ“‹{i} [role: {role}]\n"

        # å¦‚æœæ˜¯å·¥å…·æ¶ˆæ¯ï¼Œæ˜¾ç¤º tool_call_id
        if role == "tool" and tool_call_id:
            prompt_result += f"  - Tool Call ID: {tool_call_id}\n"

        if content:
            prompt_result += f"#### ğŸ’¬Content\n{split_line}{content}{split_line}"

        # å¤„ç†å·¥å…·è°ƒç”¨
        if tool_calls:
            prompt_result += f"#### ğŸ”¨Tool Calls ({len(tool_calls)})\n"
            for j, tool_call in enumerate(tool_calls):
                tool_id = tool_call.get("id", "N/A")
                tool_type = tool_call.get("type", "N/A")
                function = tool_call.get("function", {})
                function_name = function.get("name", "N/A")
                arguments = function.get("arguments", "{}")

                prompt_result += f"##### Tool Call {j}\n"
                prompt_result += f"  - ID      : {tool_id}\n"
                prompt_result += f"  - Type    : {tool_type}\n"
                prompt_result += f"  - Function: {function_name}\n"
                prompt_result += f"  - Arguments: {split_line}{format_json_text(arguments)}{split_line}\n"
    return prompt_result


def handle_tools(tools: List[Any]):
    tool_result = f"## ToolsğŸ› ï¸ ({len(tools)})\n"
    for i, tool in enumerate(tools):
        tool_name = tool["function"]["name"]
        tool_desc = tool["function"]["description"]
        tool_params = tool["function"].get("parameters", {})

        tool_result += (
            f"### ğŸ› ï¸{i}: {tool_name}\n{split_line}{indent_text(tool_desc, DEFAULT_INDENT)}{split_line}"
        )

        # Add parameters if they exist
        if tool_params:
            tool_result += f"#### Parameters:\n"
            # Convert parameters to JSON string with indentation for better readability
            params_json = json.dumps(tool_params, indent=2, ensure_ascii=False)
            tool_result += f"{split_line}{format_json_text(params_json)}{split_line}\n"
    return tool_result


class OpenaiReq(Contentview):
    name = "openai-request"
    syntax_highlight = "none"

    def prettify(
        self,
        data: bytes,
        metadata: contentviews.Metadata,
    ) -> str:
        try:
            return self.prettify_exec(data, metadata)
        except Exception as e:
            logging.error(f"Error in OpenaiReq prettify: {e}")
            return f"Error processing request: {e}"

    def prettify_exec(
        self,
        data: bytes,
        metadata: contentviews.Metadata,
    ) -> str:

        # logging.info('prettify LLM Request body')
        obj = json.loads(data)

        result = "# LLM Request body\n \n"
        result += handle_request_basis(obj)
        result += multi_line_splitter(2)
        # print(obj['messages'])
        result += handle_messages(obj.get("messages", []))
        result += multi_line_splitter(3)
        result += handle_tools(obj.get("tools", []))

        return result

    def render_priority(self, data: bytes, metadata: contentviews.Metadata) -> float:
        if (
            metadata.content_type
            and metadata.content_type.startswith("application/")
            and metadata.content_type.endswith("json")
            and metadata.flow.request.path.endswith("completions")
            and isinstance(metadata.http_message, Request)
        ):
            return 2  # return a value > 1 to make sure the custom view is automatically selected
        else:
            return 0


contentviews.add(OpenaiReq)